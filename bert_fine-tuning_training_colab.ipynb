{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert_fine-tuning_training_colab.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1yVbrpCtaoJIe_RwDwx00dApJipVqhMfw","authorship_tag":"ABX9TyOeozIAHjwAGaUhtzklfoF6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"egj26P83Uzya"},"source":["# Fine-tuning Training on Two-Tower BERT<sub>BASE</sub>\n","\n","This notebook contains fine-tuning two-tower BERT<sub>BASE</sub> model fitting for recommendation task on users and items reviews."]},{"cell_type":"code","metadata":{"id":"ohB1nITJ1EdF"},"source":["import os\n","import urllib\n","\n","from google.colab import drive, files\n","from getpass import getpass\n","\n","from google.colab import drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiQnW4Q81VqM","executionInfo":{"status":"ok","timestamp":1617582805727,"user_tz":240,"elapsed":296,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"b3353a43-6771-4ec8-ca5d-1e1d3dec86d0"},"source":["ROOT = '/content/drive'\n","GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/recommender/w266-final'\n","PROJECT_PATH = os.path.join(ROOT, GOOGLE_DRIVE_PATH)\n","\n","drive.mount(ROOT)\n","\n","%cd {PROJECT_PATH}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Colab Notebooks/recommender/w266-final\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pdb-ImP91gxi"},"source":["import os\n","import sys\n","import re\n","import pandas as pd\n","import numpy as np\n","import itertools\n","import pickle\n","import random\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from commons.store import PickleStore, NpyStore\n","from tqdm import tqdm\n","from IPython.core.display import HTML\n","from importlib import reload\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SMq4MT4_Xur_"},"source":["## 1. Load Pre-filtered Dataset\n","\n","First, we load the clean pre-processed dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MLUxSobB1m6m","executionInfo":{"status":"ok","timestamp":1617582837088,"user_tz":240,"elapsed":9360,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"aef5555b-58d5-4d8f-a8a4-3fe74618a8bc"},"source":["amazon = False\n","\n","if amazon:\n","  input_pkl = '../dataset/25-65_tokens_grouped_Movies_and_TV_v2.pkl'\n","else:\n","  input_pkl = '../dataset/25-65_tokens_grouped_yelp.pkl'\n","\n","pkl_store = PickleStore(input_pkl)\n","\n","grouped_reviews_df = pkl_store.load(asPandasDF=True, \\\n","                                    columns=['reviewerID', 'asin', 'overall', 'userReviews', 'itemReviews'])\n","print(len(grouped_reviews_df))\n","display(HTML(grouped_reviews_df.head(1).to_html()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading ../dataset/25-65_tokens_grouped_yelp.pkl ...\n","\t... 272296 records\n","Done!!\n","272296\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>reviewerID</th>\n","      <th>asin</th>\n","      <th>overall</th>\n","      <th>userReviews</th>\n","      <th>itemReviews</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>JHXQEayrDHOWGexs0dCviA</td>\n","      <td>KXCXaF5qimmtKKqnPc_LQA</td>\n","      <td>1.0</td>\n","      <td>[the dark chocolate gelato is so rich and creamy and seductiveyou must lick it once in your life but their prices recently went up so take your credit card, great pastries and chocolate but why does the service have to be soooo slow and disorganized sigh, great ice cream but are the staff handpicked for their incompetence and total lack of training the service is that bad it's almost embarrassing, great baked goods but please don't remind me 1530 minutes before you close that we are closing at 6 as it's not polite it's not etiquette it's not nice to pressure customers to hurry up thank you, it's really hokey and old but not in a good way in an ancient dirty way a good place to view a cross section of west vancouver ie grey hair it needs to be renovatedthe 'old world charm' is simply not there, the gelato is good not quite to the italian standard but hey you can't have everything thx decor is tragic and the coffee is only 'accrptable' not 'outstanding', always a staple vancouver pizzeria not pretentious but good honest nongourmet pizza and pasta nice atmosphere and good staff, very good food and a basic honest restaurant the beef ribs are the best option it's a bit of a hipster place with loud hard rick music on the loud side not atmosphere inducing service was quick and fairly efficient but not overly attentive, this place has great freshly made tempura and good quality sushi excellent down town location and efficient rather than 'friendly' staff good value too, you can drink franchise coffee and then you can drink arti's coffee the difference is massive visit him once you will never look back, this is a great place to find beautifully crafted chocolates and frenchstyled pastries the coffee is good quality too the only downside is the lack of seating and the rather hap hazard way of serving the customers, food is good and wellpriced interior decor is tragic and service a bit slow if you want a good no frills greek experience this is a reasonable choice, good snack and coffee but needs a damn good clean it's pretty clear that the staff are not happy, it's a good place but really no ambience and when you use canned bamboo shoots you know you're not going to get authentic cuisine they try hard herebut not hard enough, you can't go past their pizza slices and freshsqueezed cranberry juice gets very crowded during lunch hourbut for a good reason nice, the pizza slice es used to be great but now they have compromised on the quality of their ingredients and it's gone down quite a bit, very good baked goods especially the croissants however the service sucks big time staff have horrible attitude, the ice cream is of course very nice if a little bit expensive the service is not goodslow and miserable staff should not serving ice cream to a willing public be a happy occasion, their burgers fries and shakes are simply the best in townand very healthy the pictures below do all the talking, just go you won't be disappointedgreat pizza great service great wine and beer selection tiramisu to die for happy happy joy joy, i had lamb korma and coconut chicken curry with naan and roti breadsvery good quality food and a fir price service is a little slow 25 minute wait for food but otherwise a good indian choicenice proud owner too, it's a very quirky place and microscopicso expect a lineup the service and the deserts easily make up for the wait good prices plunger coffeegood times, this is a terrific cafe with great art shows good coffee and deserts and a lovely calm ambience tyler the owner is fabulous and really values community and creativity a must try, very cool and authentic whiskeycocktail bar it's off the beaten track but that's what makes it so great huge selection knowledgeable staff very good happy hour and decent charcuterie board definitely a must see when in portland area, it's a great location just fabuloushorrendous service  if you want to be ignored and treated with derision then this is the place for yousuch a damn shame, the happy hour choices are quite good atmosphere is fairly pedestrian and the service is very mediocre inattentive and uninterested staff, not that good honestly go to robson street location for better waffles and waaay better service, i went there for the first time about a month ago clean spa great spa pedicure prices are good and the toes came out amazing]</td>\n","      <td>[tonight the macaron du jour' was the lycheeabsolutely yummybut still the hands down favourite are the coffee andor chocolate caramel whichever i munch on first, friday's nite batch just soso the filling just oozed out of every bite just guessing wasn't chilled long enoughsigh worst ones everbut still sweet the lemon raspberry , overhyped in my opinon honestly nothing exceptional macaroons and chocolates are very standard i love their passionfruit mousse though a staple every time i visit, artistic and tasty desserts it's a pricey place and crowded with young kids so it can be noisy but the desserts are worth it  the macaroons are quite big so go nuts and enjoy  the americano was delicious, i love their macarons it's chewy and not too sweet my only complaint is that they always run out of of varieties, very happening place lots of people from all over the world we had to chose from so many desserts that looked amazing don't think you can go wrong, amazing  location  delicious thick hot chocolate and great treatswe always ho there for dessert  and we are  both impressed each time will revisit, great selection of desserts the passionfruit dome cake with mini macarons on around the bottom of the cake was delicious, the desserts here are amazing we even got a cake for a birthday and it was delicious staff are wonderful coffee could be better, kenneth n's recommendation of thierry's macarons persuaded me to returnsmooth crust chewy cookie light creamy filling reasonable sweetness that does not overpower the flavour yum i haven't had a disappointing flavour to date, fall in love with their tiramisu looks so adorable and the cream is perfect friday night is busy we sat on the patio to enjoy the late night sweet, love the desserts at this place   my favorites are the lemon tart millefeuille and chocolate marquise   busy place desserts are not cheap but worth it   love these french desserts and keep wanting to come back  staff are pretty nice and service is pretty fast, a friend treated us to a sleeve of fruitflavoured macaronsthey are so delectablebest way to eat it is so pop it whole in your mouththe berry  lemon are so goodi could eat a whole sleeve by myself, their pastries are the best in vancouver we went there on a saturday night but it was crowded as usualunfortunately choices were limited chocolate trio was awesome also the tea had a strong taste just like indian teas, sophisticated food really high quality and class but so crowded and noisy and often lacks free tables, beautiful cafe very attentive and knowledgable staff however their desserts are too sweet for me i've tried their macarons and their cakes and they're just way too sweet for me but their displays are very attractive, the macarons there are good but i think it's a bit too sweet and hard personally like soirette more the desserts are quite expensive but it's at great location to have a bakery though which is probably why, desserts and pastries are beautiful and almost is tasty try to find a quiet time otherwise you're competing with the self obsessed rude people coffee here is extra good and nice pick me up early in the day, visited last night  it's so busy on a friday night  food was great  service was fast  i love the liquid chocolate, everything i have had from thierry is to die for if you have a sweet tooth you absolutely need to try thierry, there is no place in vancouver like this omg everything is to die for i could eat their tiramisu cake everyday hahaaa since i moved back from toronto i was looking for something like this love u guys keep up the good work, since my last visit the quality bounced back up again it is simply one of the few good options you have in townthey now have two japanese baristas that makes coffee precisely and accurately it is fun to see them workpastry is good and cakes are fantastic, yes if you love french desserts this is the place to go i celebrated my birthday here and had a few of the delicacies and they were so good i'd recommend the layer cake and some of the classics it's a cute little cafe as well, the service was at best minimal coz they are under staffed also the price point is not justifiable for the quality of drinks and food better luck next time if they don't change will not come back, i had drinking chocolate and a pear danish which were superb and a croissant which was pretty good  10 for all three was neither great nor terrible but i felt it was reasonable given the high rent district, tried their coveted macaroons and an opera cake still not convinced that the place is worth returning to other than the fact that their bags are really pretty and would be really presentable as gifts, thierry is a treasure it's a wonderful place to visit with girlfriends and it's open until midnight the cakes there are amazing, i love this cafe it's one of my favorites in vancouver anything you order here will be amazing though i recommend the hot chocolate with or without liqueurs, really really good macaroons  everything else is decent too  just a nice upscale hangout place in downtown  definitely beats timmy's across the street, great upscale cafe with boozie options available  it's always packed but their outside seating is comfortable with the heaters going  their liquid chocolate is so yummy as well as their macaroons their cakes are really beautiful and they even have a gluten free cake, amazing chocolates and desserts but terrible cappuccino  unfortunately they don't know how to steam milk the way so it's nice and foamy and creamy  it's just boiling hot milk mixed with espresso  i wish they learn how to make it right, tried the forest cake and salted caramel latteboth are not my thing i didn't finish any of it, this is my late night downtown dessert place the service is always friendly and the dessert displays never fail to nudge my appetite  even after dinner i love the lively atmosphere and how i can chat and catch up with a girlfriend without feeling pressured to leave even once it gets busy, great patio season  just walked over for some macaroons and tea i love this place for a late night treat in the summer  it's only april but it's hot enough to sit out yay, best place ever if you have a sweet tooth i love pretty much everything from the deserts to the drinks great service and also for it being packed in the evenings the staff work fast and efficient, good fresh ingredients and pastriessweets found it to be a bit pricey so i won't be a regular customer but is popular in vancouver, awesome dessert and macarons  it's always busy during weekends which makes it hard to find a table to enjoy your dessert, great after dinner spot for dessert and coffee  this place is trendy and expensive but given the area i understandthe desserts cakes are just right  not too sweet or creamylooks like the serve alcohol too, cute little pastrychocolate shop in downtown vancouver on alberni street they have the best tiramisu and palmiers but i find that thomas haas has a better selection and quality it is great that they're open late and also serve alcohol, run by the same folks behind blue water cafe grabbed a decent pain au chocolat here before stanley park, tiramisu is my to go desert  love it and also pair with london fog tea  im in heaven lalalala, hands down favourite place to have desert and tea it is a known fine dining desert place so be ready to wait for seat deserts and tea are phenomenal definitely recommend to stop by if you are in the neighbourhood, 6 of us dropped in for a little treatit was my1st time and it was a pleasant surprise  excellence is all over this place in every way  you won't be disappointed at thierry, i love it when places stay consistent  after a year their desserts are still just as good  sure the price tag is sometimes a little high but in my opinion they are worth it, best macarons ever and the lattes are great nothing else i've tried has really stood out to me as being that amazing stick to the macarons they're outstanding my favourite flavours cassis lemoncherry  lychee, sandwiches should be warm coffee is too hot always bad baristas i burned my tongue many times other than that they are always open holidays weekends late nights lots of seats napoleon is delicious, not even the aggressive couple behind me in line who tried to edge me out with their stroller loaded with tiffany's bags could stop me from coming here again  just tried their macarons but holy crap were they delicious  plus their selection of wobbly coffees is amazing, i got the macarons here and they were pretty good but it would've been nice if there was more selection, i love the desserts and coffee at this place is really good place to sit and relaxlove the passion cake and london fog here, i don't usually eat anything related to chocolate but cannot say no to theirry's chocolate marquise they also have the best tiramisu in town, winner winner chocolate for dinner macaroons and the triple layer chocolate cake are 10s just try and you will know that chef thierry knows desserts i am happy that i got to try the treats oh and the hot chocolate was just right, their hot chocolate is good  their macaroons are too sweet  not a fan  overpriced food and drinks but once in a while is okay , expensive but tasty chocolate treats decent coffee in an area with few options outdoor seating is nice if you can get a seat often very busy pretty wood panel decori prefer 49th parallel one block away it has much better coffee and some of the best donuts in the city, knocking it down one star because of the lack of selection for macaron flavors i'm assuming that flavors tend to run out later in the day the only thing i wanted to get was the salted caramel and it would've been extremely disappointing if they didn't have that, a great place to enjoy a conversation over very good coffee and pastries interior is well done and comfortable they have a mixture of small tables and adirondack chairs outsidethe cinnamon rolls here are doughy and heavy on the icing]</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Pp3vlAR6FthI"},"source":["We select columns that are relevant and covert them to numpy array."]},{"cell_type":"code","metadata":{"id":"HRSkA_1718GM"},"source":["\n","grouped_reviews = grouped_reviews_df[['reviewerID', 'asin', 'overall', 'userReviews', 'itemReviews']].to_numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fbk55zG2F1I3"},"source":["We detect hardware and based on the outcome, we define the accelerator strategy."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HQ_R1v031JZ","executionInfo":{"status":"ok","timestamp":1617582849150,"user_tz":240,"elapsed":945,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"47b80fd5-d4f9-4ddf-f265-8ceb5490c4dc"},"source":["# Detect hardware\n","try:\n","  tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n","except ValueError:\n","  tpu_resolver = None\n","  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n","\n","# Select appropriate distribution strategy\n","if tpu_resolver:\n","  tf.config.experimental_connect_to_cluster(tpu_resolver)\n","  tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n","  print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n","elif len(gpus) > 1:\n","  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n","  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n","elif len(gpus) == 1:\n","  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n","  print('Running on single GPU ', gpus[0].name)\n","else:\n","  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n","  print('Running on CPU')\n","  \n","print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on single GPU  /device:GPU:0\n","Number of accelerators:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WpFbpkSGXxO1","executionInfo":{"status":"ok","timestamp":1617582855474,"user_tz":240,"elapsed":3538,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"bb5eef4c-53fa-40ea-e1e5-b2836e5eb450"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pf0r0GgB4ZyX"},"source":["import tensorflow as tf\n","\n","from transformers import BertTokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LKUjnr0lX9x4"},"source":["Here, we load BERT tokenizer using BERT huggingface <img src='https://huggingface.co/front/assets/huggingface_logo.svg' width='20px'> library."]},{"cell_type":"code","metadata":{"id":"nF533QBe4nri"},"source":["bert_model_name = 'bert-base-uncased'\n","\n","MAX_LEN = 64\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","NO_EPOCHS = 30\n","BUFFER_SIZE = 100\n","\n","with strategy.scope():\n","  tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frCYAKbtZGph"},"source":["## 2. Train, Validation, and Test Split\n","\n","We split our dataset to train, validation, and test and ensure there is no leak among those.\n","\n","For the model fitting, we use `MAX_LEN=64` with `BATCH_SIZE=16` and `NO_EPOCHS=30`. We take those considerations such that we can fit our model into a single GPU because of extremely large trainable parameters."]},{"cell_type":"code","metadata":{"id":"1KmF5_sg4vXQ"},"source":["def train_test_split(reviews, test_percent=0.1):\n","    \"\"\"train and test split based on given test percentage\"\"\"\n","    \n","    samples = len(reviews)\n","\n","    train_size = int((1 - test_percent) * samples)\n","    train = reviews[:train_size]\n","    test = reviews[train_size:]\n","\n","    return train, test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ql_D-b244_x"},"source":["np.random.seed(111)\n","np.random.shuffle(grouped_reviews)\n","\n","# split for train and test\n","\n","if amazon:\n","  test_percent=0.007\n","else:\n","  test_percent=0.01\n","\n","train, test = train_test_split(grouped_reviews, test_percent=test_percent)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ce3_4hGh5HOb"},"source":["test_revId_uniques = np.unique(test[:,0])\n","test_asin_uniques = np.unique(test[:,1])\n","\n","# only pick test reviewerID and asin that are not in train\n","train = train[np.isin(train[:,0], test_revId_uniques, invert=True, assume_unique=True)]\n","train = train[np.isin(train[:,1], test_asin_uniques, invert=True, assume_unique=True)]\n","\n","# split again for train and validation\n","if amazon:\n","  val_percent=0.05\n","else:\n","  val_percent=0.08\n","train, val = train_test_split(train, test_percent=val_percent) # , \n","\n","val_revId_uniques = np.unique(val[:,0])\n","val_asin_uniques = np.unique(val[:,1])\n","\n","# only pick val reviewerID and asin that are not in train\n","train = train[np.isin(train[:,0], val_revId_uniques, invert=True, assume_unique=True)]\n","train = train[np.isin(train[:,1], val_asin_uniques, invert=True, assume_unique=True)]\n","\n","\n","# pick and rearrange to userReviews, itemReviews, overall\n","train = train[:, [3, 4, 2]]\n","val = val[:, [3, 4, 2]]\n","test = test[:, [3, 4, 2]]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SVitYKw8Q35"},"source":["def __tokenize(reviews, tokenizer, max_len):\n","    return tokenizer(list(reviews), padding='max_length', truncation=True, max_length=max_len, return_tensors='tf') \n","\n","def create_tensor_dataset(samples, tokenizer, max_len=128):\n","  \"\"\"generate dataset to tensorflow dataset format for two-tower network\"\"\"\n","\n","  def gen():\n","    for i, reviews in enumerate(samples):\n","      # tokenize each group of users and items reviews\n","      user_tokens = __tokenize(reviews[0], tokenizer, max_len)\n","      item_tokens = __tokenize(reviews[1], tokenizer, max_len)\n","\n","      yield ({'user_input_ids': [user_tokens.data['input_ids']],\n","              'user_token_type_ids': [user_tokens.data['token_type_ids']], \n","              'user_attention_masks': [user_tokens.data['attention_mask']],\n","              'item_input_ids': [item_tokens.data['input_ids']],\n","              'item_token_type_ids': [item_tokens.data['token_type_ids']],\n","              'item_attention_masks': [item_tokens.data['attention_mask']]}, \n","             {'label': [reviews[2]]})\n","  \n","  # generator with output signature\n","  dataset = tf.data.Dataset.from_generator(\n","      gen, \n","      output_signature=({'user_input_ids': tf.TensorSpec(shape=(None, None, max_len), dtype=tf.int32),\n","                        'user_token_type_ids': tf.TensorSpec(shape=(None, None, max_len), dtype=tf.int32),\n","                        'user_attention_masks': tf.TensorSpec(shape=(None, None, max_len), dtype=tf.int32),\n","                        'item_input_ids': tf.TensorSpec(shape=(None, None, max_len), dtype=tf.int32),\n","                        'item_token_type_ids': tf.TensorSpec(shape=(None, None, max_len), dtype=tf.int32),\n","                        'item_attention_masks': tf.TensorSpec(shape=(None, None, max_len), dtype=tf.int32)},\n","                        {'label':tf.TensorSpec(shape=(None), dtype=tf.float32)})\n","  )\n","\n","  return dataset\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x5ifuy6cZ1wA"},"source":["Because of the variant number of reviews on each grouped of users and items reviews, only tensorflow Dataset API with `from_generator` can support to format our dataset and be fitted to our two-tower BERT<sub>BASE</sub> model. The drawback is the training cannot be parallelized to multiple accelerators because the generator itself is a python function, and therefore tensorflow is unable to serialize that function to multiple accelerators strategy. This method, however, can support for streaming large dataset and generate the dataset by batches to fit into the model."]},{"cell_type":"code","metadata":{"id":"wSyY9Yq-BRPn"},"source":["train_dataset = create_tensor_dataset(train, tokenizer=tokenizer, \n","                                      max_len=MAX_LEN)\n","\n","val_dataset = create_tensor_dataset(val, tokenizer=tokenizer, \n","                                    max_len=MAX_LEN)\n","\n","test_dataset = create_tensor_dataset(test, tokenizer=tokenizer, \n","                                     max_len=MAX_LEN)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pptVeJmVCYHd"},"source":["## 3. Model Definition and Callbacks\n","\n","We use Two-tower network for our model where each tower learns latent feature representation of user and item reviews respectively. We apply layer normalization and dropout of $0.2$ for regularization to prevent overfitting.\n","\n","BERT huggingface <img src='https://huggingface.co/front/assets/huggingface_logo.svg' width='20px'> library is used for our BERT<sub>BASE</sub> model."]},{"cell_type":"code","metadata":{"id":"8qZKpiihCgRT"},"source":["from transformers import TFBertModel, BertConfig\n","\n","from tensorflow.keras import Model, Input\n","from tensorflow.keras.layers import Layer, Flatten, Concatenate, Dense, Add, Dot, Dropout, GlobalAveragePooling2D, LayerNormalization\n","from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n","\n","%load_ext tensorboard\n","\n","class BertLayer(Layer):\n","\n","  def __init__(self, config, max_len):\n","    super().__init__()\n","\n","    self.config = config\n","    self.max_len = max_len\n","    self.bert = TFBertModel.from_pretrained(bert_model_name, config=self.config)\n","\n","  def call(self, input):\n","    return tf.map_fn(\n","      lambda x: self.bert(x).last_hidden_state,\n","      dtype=tf.int32,\n","      elems=input,\n","      fn_output_signature=tf.TensorSpec(shape=(None, self.max_len, 768), dtype=tf.float32)\n","    )\n","\n","class RecommenderClassifier():\n","  def __init__(self, bert_config, max_len=128, hidden_dim=32, rate=0.1):\n","\n","      self.bert_config = bert_config\n","      self.max_len = max_len\n","      self.hidden_dim = hidden_dim\n","\n","      self.layernorm = LayerNormalization(epsilon=1e-6)\n","\n","      self.user_ids, self.user_token_types, self.user_masks, self.user_tower = self.__create_tower('user')\n","      self.item_ids, self.item_token_types, self.item_masks, self.item_tower = self.__create_tower('item')\n","      self.joined = Concatenate()([self.user_tower, self.item_tower])\n","      self.dropout = Dropout(rate)(self.joined)\n","      self.out_1 = Dense(1)(self.dropout)\n","\n","\n","  def __create_tower(self, name):\n","    input_ids_layer = Input(shape=(None, self.max_len), name=f'{name}_input_ids', dtype=tf.int32)\n","    token_type_ids_layer = Input(shape=(None, self.max_len), name=f'{name}_token_type_ids', dtype=tf.int32)\n","    attention_mask_layer = Input(shape=(None, self.max_len), name=f'{name}_attention_masks', dtype=tf.int32)\n","\n","    bert_layer = BertLayer(self.bert_config, self.max_len)\n","    input_embedding = bert_layer([input_ids_layer, attention_mask_layer, token_type_ids_layer])\n","    mean_embedding = GlobalAveragePooling2D(name=f'{name}_mean')(input_embedding)\n","\n","    tower = Dense(self.hidden_dim, activation=\"relu\", name=f'{name}_dense')(mean_embedding)\n","    tower = self.layernorm(tower)\n","\n","    return input_ids_layer, token_type_ids_layer, attention_mask_layer, tower\n","  \n","\n","  def build_model(self):\n","    dotproduct = Dot(axes=1)([self.user_tower, self.item_tower])\n","    output = Add(name='label')([self.out_1, dotproduct])\n","    \n","    model = Model(inputs=[self.user_ids, self.user_token_types, self.user_masks, \n","                          self.item_ids, self.item_token_types, self.item_masks], \n","                  outputs=[output])\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vukHicHWNNxp","executionInfo":{"status":"ok","timestamp":1617583312998,"user_tz":240,"elapsed":43512,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"1f72820c-0e48-4acc-8ff3-0a44d3a3eede"},"source":["config = BertConfig()\n","config.output_hidden_states = True # set to True to obtain hidden states\n","\n","with strategy.scope():\n","  loss_fn = tf.keras.losses.MeanSquaredError()\n","  adam = tf.keras.optimizers.Adam(learning_rate=0.00002) # 0.000002\n","  mse_metrics = tf.keras.metrics.MeanSquaredError()\n","\n","  classifier = RecommenderClassifier(config, max_len=MAX_LEN, rate=0.2)\n","  model = classifier.build_model()\n","\n","  model.compile(optimizer=adam, loss=loss_fn, metrics=[mse_metrics])\n","  model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa0188e6d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa0188e6d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fa044190c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7fa044190c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","user_input_ids (InputLayer)     [(None, None, 64)]   0                                            \n","__________________________________________________________________________________________________\n","user_attention_masks (InputLaye [(None, None, 64)]   0                                            \n","__________________________________________________________________________________________________\n","user_token_type_ids (InputLayer [(None, None, 64)]   0                                            \n","__________________________________________________________________________________________________\n","item_input_ids (InputLayer)     [(None, None, 64)]   0                                            \n","__________________________________________________________________________________________________\n","item_attention_masks (InputLaye [(None, None, 64)]   0                                            \n","__________________________________________________________________________________________________\n","item_token_type_ids (InputLayer [(None, None, 64)]   0                                            \n","__________________________________________________________________________________________________\n","bert_layer (BertLayer)          (None, None, 64, 768 109482240   user_input_ids[0][0]             \n","                                                                 user_attention_masks[0][0]       \n","                                                                 user_token_type_ids[0][0]        \n","__________________________________________________________________________________________________\n","bert_layer_1 (BertLayer)        (None, None, 64, 768 109482240   item_input_ids[0][0]             \n","                                                                 item_attention_masks[0][0]       \n","                                                                 item_token_type_ids[0][0]        \n","__________________________________________________________________________________________________\n","user_mean (GlobalAveragePooling (None, 768)          0           bert_layer[0][0]                 \n","__________________________________________________________________________________________________\n","item_mean (GlobalAveragePooling (None, 768)          0           bert_layer_1[0][0]               \n","__________________________________________________________________________________________________\n","user_dense (Dense)              (None, 32)           24608       user_mean[0][0]                  \n","__________________________________________________________________________________________________\n","item_dense (Dense)              (None, 32)           24608       item_mean[0][0]                  \n","__________________________________________________________________________________________________\n","layer_normalization (LayerNorma (None, 32)           64          user_dense[0][0]                 \n","                                                                 item_dense[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 64)           0           layer_normalization[0][0]        \n","                                                                 layer_normalization[1][0]        \n","__________________________________________________________________________________________________\n","dropout_74 (Dropout)            (None, 64)           0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            65          dropout_74[0][0]                 \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 1)            0           layer_normalization[0][0]        \n","                                                                 layer_normalization[1][0]        \n","__________________________________________________________________________________________________\n","label (Add)                     (None, 1)            0           dense[0][0]                      \n","                                                                 dot[0][0]                        \n","==================================================================================================\n","Total params: 219,013,825\n","Trainable params: 219,013,825\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YQg8w40lRRYR"},"source":["# Tensorboard and checpoint callbacks\n","\n","def tensorboard_checkpoint_callbacks(name):\n","\n","  if amazon:\n","    tensorboard_dir = ''.join(['./logs/tensorboard/', name])\n","  else:\n","    tensorboard_dir = ''.join(['./yelp/logs/tensorboard/', name])\n","\n","  if not os.path.exists(tensorboard_dir):\n","      os.makedirs(tensorboard_dir)\n","\n","  version = 1\n","  dirs = [d for d in os.listdir(tensorboard_dir) if not d.startswith('.')]\n","\n","  if (len(dirs) > 0):\n","      versions = np.asarray(list(map(lambda v: int(v[1:]), dirs)))\n","      version = versions[versions.argsort()[::-1][0]]\n","      version += 1\n","\n","  tensorboard_version_dir = os.path.join(tensorboard_dir, ''.join(['v', str(version)]))\n","  print(tensorboard_version_dir)\n","\n","  tensorboard_callback = TensorBoard(log_dir=tensorboard_version_dir, histogram_freq=1)\n","\n","  if amazon:\n","    checkpoint_dir = './logs/chkpoint'\n","  else:\n","    checkpoint_dir = './yelp/logs/chkpoint'\n","\n","  checkpoint_name_dir = os.path.join(checkpoint_dir, name, ''.join(['v', str(version)]))\n","  if not os.path.exists(checkpoint_name_dir):\n","      os.makedirs(checkpoint_name_dir)\n","\n","  checkpoint_file = os.path.join(checkpoint_name_dir, 'weights.best.hdf5')\n","\n","  print(checkpoint_file)\n","  checkpoint_callback = ModelCheckpoint(checkpoint_file, monitor='val_loss', verbose=0, save_best_only=True, \n","                                        save_weights_only=True)\n","  \n","  return tensorboard_callback, checkpoint_callback, version\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQQD2YamHDuj","executionInfo":{"status":"ok","timestamp":1617583322604,"user_tz":240,"elapsed":736,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"cfc8530b-fd7e-49a1-b41f-aa8419d4a42b"},"source":["name = 'finetuned'\n","tensorboard_callback, checkpoint_callback, version = tensorboard_checkpoint_callbacks(name)\n","lr_onplateau_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./yelp/logs/tensorboard/finetuned/v1\n","./yelp/logs/chkpoint/finetuned/v1/weights.best.hdf5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"UD0oJTP9S4DE","executionInfo":{"status":"ok","timestamp":1617583329492,"user_tz":240,"elapsed":753,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"31ef3610-65e7-4a08-8876-0966eae885de"},"source":["# Early stopping callback\n","earlystop_callback = EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=10)\n","\n","# Learning rate scheduler callback\n","# optimizer (with 1-cycle-policy)\n","start_lr = 0.00001\n","min_lr = 0.00001\n","max_lr = 0.001 * strategy.num_replicas_in_sync\n","rampup_epochs = 10\n","sustain_epochs = 0\n","exp_decay = .9\n","\n","def lrfn(epoch):\n","  if epoch < rampup_epochs:\n","    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n","  elif epoch < rampup_epochs + sustain_epochs:\n","    return max_lr\n","  else:\n","    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n","\n","lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n","\n","rang = np.arange(NO_EPOCHS)\n","y = [lrfn(x) for x in rang]\n","plt.plot(rang, y)\n","print('Learning rate per epoch:')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning rate per epoch:\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"mrbXeTXsct3-"},"source":["## 4. Model Fitting\n","\n","We train our recommendation classifier model with MSE loss function and Adam optimizer with initial learning rate of $2e^{-5}$. We also apply tensorboard, checkpoint and learning rate reduce on plateau with factor of $0.2$ and patience of $5$ as callbacks.\n","\n","We experimented with one-cycle-policy learning rate scheduler, however it appears that learning rate reduce on plateau performs better on fine-tuning approach."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uddzFE5TQTrB","executionInfo":{"status":"ok","timestamp":1617596294384,"user_tz":240,"elapsed":12958452,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"dbc42165-dfd2-442a-ef9c-d538ebdd74e3"},"source":["%%time\n","train_size = len(train)\n","train_steps_per_epoch = train_size // BATCH_SIZE\n","\n","val_size = len(val)\n","val_steps_per_epoch = val_size // BATCH_SIZE\n","\n","history = model.fit(train_dataset.shuffle(BUFFER_SIZE), \n","                    batch_size=BATCH_SIZE,\n","                    steps_per_epoch=train_steps_per_epoch,\n","                    validation_data=val_dataset,\n","                    validation_steps=val_steps_per_epoch,\n","                    callbacks=[lr_onplateau_callback, tensorboard_callback, checkpoint_callback], #  lr_callback , earlystop_callback\n","                    epochs=NO_EPOCHS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer BertLayer has arguments in `__init__` and therefore must override `get_config`.\n","Epoch 1/30\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","1462/1462 [==============================] - ETA: 0s - loss: 6.9606 - mean_squared_error: 6.9606WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","1462/1462 [==============================] - 914s 541ms/step - loss: 6.9579 - mean_squared_error: 6.9579 - val_loss: 1.5453 - val_mean_squared_error: 1.5453\n","Epoch 2/30\n","1462/1462 [==============================] - 772s 528ms/step - loss: 1.8724 - mean_squared_error: 1.8724 - val_loss: 1.3124 - val_mean_squared_error: 1.3124\n","Epoch 3/30\n","1462/1462 [==============================] - 773s 529ms/step - loss: 1.8499 - mean_squared_error: 1.8499 - val_loss: 1.1583 - val_mean_squared_error: 1.1583\n","Epoch 4/30\n","1462/1462 [==============================] - 768s 525ms/step - loss: 1.6981 - mean_squared_error: 1.6981 - val_loss: 1.1989 - val_mean_squared_error: 1.1989\n","Epoch 5/30\n","1462/1462 [==============================] - 762s 521ms/step - loss: 1.6965 - mean_squared_error: 1.6965 - val_loss: 1.1918 - val_mean_squared_error: 1.1918\n","Epoch 6/30\n","1462/1462 [==============================] - 768s 526ms/step - loss: 1.7010 - mean_squared_error: 1.7010 - val_loss: 1.1635 - val_mean_squared_error: 1.1635\n","Epoch 7/30\n","1462/1462 [==============================] - 782s 535ms/step - loss: 1.4816 - mean_squared_error: 1.4816 - val_loss: 1.1594 - val_mean_squared_error: 1.1594\n","Epoch 8/30\n","1462/1462 [==============================] - 781s 534ms/step - loss: 1.4821 - mean_squared_error: 1.4821 - val_loss: 1.2782 - val_mean_squared_error: 1.2782\n","\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n","Epoch 9/30\n","1462/1462 [==============================] - 774s 530ms/step - loss: 1.3935 - mean_squared_error: 1.3935 - val_loss: 1.1551 - val_mean_squared_error: 1.1551\n","Epoch 10/30\n","1462/1462 [==============================] - 779s 533ms/step - loss: 1.4689 - mean_squared_error: 1.4689 - val_loss: 1.1222 - val_mean_squared_error: 1.1222\n","Epoch 11/30\n","1462/1462 [==============================] - 781s 534ms/step - loss: 1.4366 - mean_squared_error: 1.4366 - val_loss: 1.1969 - val_mean_squared_error: 1.1969\n","Epoch 12/30\n","1462/1462 [==============================] - 775s 530ms/step - loss: 1.3914 - mean_squared_error: 1.3914 - val_loss: 1.1206 - val_mean_squared_error: 1.1206\n","Epoch 13/30\n","1462/1462 [==============================] - 776s 531ms/step - loss: 1.4893 - mean_squared_error: 1.4893 - val_loss: 1.1107 - val_mean_squared_error: 1.1107\n","Epoch 14/30\n","1462/1462 [==============================] - 765s 523ms/step - loss: 1.3894 - mean_squared_error: 1.3894 - val_loss: 1.3142 - val_mean_squared_error: 1.3142\n","Epoch 15/30\n","1462/1462 [==============================] - 761s 521ms/step - loss: 1.4912 - mean_squared_error: 1.4912 - val_loss: 1.1169 - val_mean_squared_error: 1.1169\n","Epoch 16/30\n","1462/1462 [==============================] - 764s 522ms/step - loss: 1.4417 - mean_squared_error: 1.4417 - val_loss: 1.0954 - val_mean_squared_error: 1.0954\n","Epoch 17/30\n","  15/1462 [..............................] - ETA: 9:13 - loss: 2.2694 - mean_squared_error: 2.2694WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 43860 batches). You may need to use the repeat() function when building your dataset.\n","1462/1462 [==============================] - 152s 103ms/step - loss: 2.3738 - mean_squared_error: 2.3738 - val_loss: 1.1012 - val_mean_squared_error: 1.1012\n","CPU times: user 5h 29min 30s, sys: 1h 5min 24s, total: 6h 34min 54s\n","Wall time: 3h 35min 58s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OAR3JSrCeDch"},"source":["## 5. Model Evaluation\n","\n","We evaluate our model using hold-out test dataset to obtain the final MSE. Subsequently, we save our model's weights only on those that have better performance."]},{"cell_type":"code","metadata":{"id":"mUu6Uf6JeqrN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617596852502,"user_tz":240,"elapsed":12807750,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"785cfb48-6141-4af5-b70a-36f3a0f10380"},"source":["mse, _ = model.evaluate(test_dataset)\n","print(f'Test MSE: {mse}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2723/2723 [==============================] - 558s 205ms/step - loss: 1.0797 - mean_squared_error: 1.0797\n","Test MSE: 1.0797028541564941\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CJcn676GSq87"},"source":["model_dir = './model'\n","\n","if not os.path.exists(model_dir):\n","    os.makedirs(model_dir)\n","\n","if amazon:\n","  model_file = ''.join([model_dir, '/recommender_', name, '_64_v', str(version), '.h5'])\n","else:\n","  model_file = ''.join([model_dir, '/yelp_recommender_', name, '_64_v', str(version), '.h5'])\n","\n","model.save_weights(model_file, save_format='h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"sPn1Fog16Jkc","executionInfo":{"status":"ok","timestamp":1617597507750,"user_tz":240,"elapsed":351,"user":{"displayName":"Sony Wicaksono","photoUrl":"","userId":"05289514665097855798"}},"outputId":"ce6846a8-8b2c-45e4-cb23-1325a11b8393"},"source":["model_file"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./model/yelp_recommender_finetuned_64_v1.h5'"]},"metadata":{"tags":[]},"execution_count":23}]}]}